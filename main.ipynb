{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code\n",
    "\n",
    "Using Python 3.11.8\n",
    "\n",
    "### Master dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install matplotlib\n",
    "%pip install split-folders\n",
    "%pip install pipreqs\n",
    "%pip install subprocess\n",
    "%pip install scikit-learn\n",
    "%pip install lime\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving dependencies to requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "installed_packages = subprocess.check_output(['pip', 'freeze']).decode('utf-8').strip().split('\\n')\n",
    "local_packages = [pkg for pkg in installed_packages if pkg.startswith('-e') or '==' in pkg]\n",
    "\n",
    "with open('requirements.txt', 'w') as file:\n",
    "    for pkg in local_packages:\n",
    "        file.write(pkg + '\\n')\n",
    "\n",
    "print(\"Requirements saved to requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import splitfolders \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import RandomVerticalFlip\n",
    "from torchvision.transforms import RandomHorizontalFlip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Pre Processing Data\n",
    "\n",
    "Resizing the images (so they each have the same amount of pixels, not to overfit to larger images) and converting them to Tensor, to find the mean and standard deviation of each channel (R, G and B) of the images. This will be used to normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([Resize(size=(64, 64)),ToTensor()])\n",
    "\n",
    "dataset = ImageFolder(root=f\"{root}/segdata\", transform=transform)\n",
    "\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "num_pixels = 0\n",
    "\n",
    "for image, _ in dataset:\n",
    "    means += torch.mean(image, dim=(1, 2))\n",
    "    stds += torch.std(image, dim=(1, 2))\n",
    "    num_pixels += image.size(1) * image.size(2)\n",
    "\n",
    "means /= len(dataset)\n",
    "stds /= len(dataset)\n",
    "\n",
    "means = means.tolist()\n",
    "stds = stds.tolist()\n",
    "\n",
    "print(\"Mean:\", means)\n",
    "print(\"Standard Deviation:\", stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train, validation and test sets of size 70%, 20% and 10% respectively, before applying normalization and other data augmentation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio(f\"{root}/segdata\", output=f\"{root}/splitted_data\", seed=42,ratio=(.7, .2, .1), group_prefix=None,move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = Compose([RandomHorizontalFlip(), RandomVerticalFlip(), Resize(size=(64,64)), ToTensor(),Normalize(mean=means, std=stds)])\n",
    "\n",
    "dataset = ImageFolder(root=f\"{root}/segdata\")\n",
    "image = dataset[9][0]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(transform(image).permute(1, 2, 0))\n",
    "plt.title('Original Image')\n",
    "\n",
    "transformed_image = transform_train(image)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(transformed_image.permute(1, 2, 0))  # Assuming transformed_image is a torch.Tensor\n",
    "plt.title('Transformed Image')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
