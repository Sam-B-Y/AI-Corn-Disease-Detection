{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOTS5m3f_cON"
      },
      "source": [
        "### Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxtDWpGD_cOO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "from tqdm import notebook as tqdm\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Normalize\n",
        "from torchvision.transforms import RandomVerticalFlip\n",
        "from torchvision.transforms import RandomHorizontalFlip\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qib0Py_1_cOO"
      },
      "source": [
        "## Loading and Pre Processing Data\n",
        "\n",
        "Resizing the images (so they each have the same amount of pixels, not to overfit to larger images) and converting them to Tensor, so they can be used in the model.\n",
        "\n",
        "Import the data from Google Drive as we assume that this is running on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV5Neyg4_cOP"
      },
      "outputs": [],
      "source": [
        "means = [0.43766510486602783, 0.49804747104644775, 0.3756938874721527]\n",
        "stds = [0.16779577732086182, 0.1552586406469345, 0.1632111817598343]\n",
        "transform_train = Compose([RandomHorizontalFlip(), RandomVerticalFlip(), Resize(size=(64,64)), ToTensor(),Normalize(mean=means, std=stds)])\n",
        "transform_val = Compose([Resize(size=(64,64)), ToTensor(),Normalize(mean=means, std=stds)])\n",
        "transform_test = Compose([Resize(size=(64,64)), ToTensor(),Normalize(mean=means, std=stds)])\n",
        "\n",
        "train_dataset = ImageFolder(root=\"/content/drive/MyDrive/splitted_data/train\",transform=transform_train)\n",
        "val_dataset = ImageFolder(root=\"/content/drive/MyDrive/splitted_data/val\",transform=transform_val)\n",
        "test_dataset = ImageFolder(root=\"/content/drive/MyDrive/splitted_data/test\",transform=transform_test)\n",
        "diffBg_dataset = ImageFolder(root=\"/content/drive/MyDrive/diffBg\",transform=transform_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh1v9Eub_cOP"
      },
      "source": [
        "### Use a GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2xo6E8M_cOP",
        "outputId": "d2421910-2bd1-4527-8b4d-2a4440b2b816"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NULTmc88_cOQ"
      },
      "source": [
        "## Defining the InceptionV1 Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEZ8yS1N_cOQ"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_chanels, **kwargs):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_chanels, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_chanels)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return F.relu(self.bn(self.conv(x)))\n",
        "\n",
        "\n",
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_channels, \n",
        "        out_1x1,\n",
        "        red_3x3,\n",
        "        out_3x3,\n",
        "        red_5x5,\n",
        "        out_5x5,\n",
        "        out_pool,\n",
        "    ):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "        self.branch1 = ConvBlock(in_channels, out_1x1, kernel_size=1)\n",
        "        self.branch2 = nn.Sequential(\n",
        "            ConvBlock(in_channels, red_3x3, kernel_size=1, padding=0),\n",
        "            ConvBlock(red_3x3, out_3x3, kernel_size=3, padding=1),\n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            ConvBlock(in_channels, red_5x5, kernel_size=1),\n",
        "            ConvBlock(red_5x5, out_5x5, kernel_size=5, padding=2),\n",
        "        )\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
        "            ConvBlock(in_channels, out_pool, kernel_size=1),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        branches = (self.branch1, self.branch2, self.branch3, self.branch4)\n",
        "        return torch.cat([branch(x) for branch in branches], 1)\n",
        "\n",
        "\n",
        "class InceptionAux(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(InceptionAux, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=0.7)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=5, stride=3, padding=1)\n",
        "        self.conv = ConvBlock(in_channels, 128, kernel_size=1)\n",
        "        self.fc1 = nn.Linear(128, 1024) \n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class InceptionV1(nn.Module):\n",
        "    def __init__(self, aux_logits=True, num_classes=4):\n",
        "        super(InceptionV1, self).__init__()\n",
        "        self.aux_logits = aux_logits\n",
        "        self.conv1 = ConvBlock(\n",
        "            in_channels=3, \n",
        "            out_chanels=64,\n",
        "            kernel_size=(7, 7),\n",
        "            stride=(2, 2),\n",
        "            padding=(3, 3),\n",
        "        )\n",
        "        self.conv2 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=2, stride=1)\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "        \n",
        "        if self.aux_logits:\n",
        "            self.aux1 = InceptionAux(512, num_classes)\n",
        "            self.aux2 = InceptionAux(528, num_classes)\n",
        "        else:\n",
        "            self.aux1 = self.aux2 = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.inception4a(x)\n",
        "        \n",
        "        if self.aux_logits and self.training:\n",
        "            aux1 = self.aux1(x)\n",
        "        \n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        \n",
        "        if self.aux_logits and self.training:\n",
        "            aux2 = self.aux2(x)\n",
        "        \n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        if self.aux_logits and self.training:\n",
        "            return aux1, aux2, x\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform a sanity check for the correctness of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = InceptionV1()\n",
        "net = net.to(device)\n",
        "data = torch.randn(5,3,64,64)\n",
        "data = data.to(device)\n",
        "out = net.forward(data)\n",
        "assert(out.detach().cpu().numpy().shape == (5,4)) # Only works if I write ...out[2].detach()...\n",
        "print(\"Forward pass successful, shape matches\")\n",
        "\n",
        "for layer in net.children():\n",
        "  print(layer)\n",
        "  print(sum(p.numel() for p in layer.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7ZESNKI_cOQ"
      },
      "source": [
        "### Move data and the model to the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddi0gqrJ_cOQ",
        "outputId": "c51d444c-06ea-4ab4-e43d-52c5fe550bb6"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size=128, shuffle=True)\n",
        "test_dl = DataLoader(test_dataset, batch_size=16)\n",
        "diffBg_dl = DataLoader(diffBg_dataset, batch_size=16)\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining a Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "INITIAL_LR = 0.1 # initial learning rate\n",
        "MOMENTUM = 0.9 # momentum for optimizer\n",
        "\n",
        "REG = 1e-3 # L2 regularization strength\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "\n",
        "# Add optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay = REG)\n",
        "EPOCHS = 30\n",
        "CHECKPOINT_FOLDER = \"./saved_model\"\n",
        "\n",
        "best_val_acc = 0\n",
        "current_learning_rate = INITIAL_LR\n",
        "\n",
        "DECAY_EPOCHS = 10\n",
        "DECAY = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "for i in range(0, EPOCHS):\n",
        "    if i % DECAY_EPOCHS == 0 and i != 0:\n",
        "        current_learning_rate = current_learning_rate * DECAY\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = current_learning_rate\n",
        "        print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "\n",
        "    net.train() # switch to train mode\n",
        "\n",
        "    print(\"Epoch %d:\" %i)\n",
        "    total_examples = 0\n",
        "    correct_examples = 0\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    # 1 epoch training\n",
        "    for batch_idx, (inputs, targets) in tqdm.tqdm(enumerate(train_dl), \"training...\"):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = net.forward(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # count the number of correctly predicted samples in the current batch\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1) \n",
        "        correct = predicted.eq(targets).sum()\n",
        "\n",
        "        correct_examples += correct\n",
        "        total_examples += len(targets)\n",
        "        train_loss += loss\n",
        "\n",
        "    avg_loss = train_loss / len(train_dl)\n",
        "    avg_acc = correct_examples / total_examples\n",
        "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
        "    \n",
        "    history['train_loss'].append(avg_loss)\n",
        "    history['train_acc'].append(avg_acc)\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    total_examples = 0\n",
        "    correct_examples = 0\n",
        "\n",
        "    val_loss = 0 \n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in tqdm.tqdm(enumerate(val_dl), \"validating...\"):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = net.forward(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct = predicted.eq(targets).sum()\n",
        "\n",
        "            correct_examples += correct\n",
        "            total_examples += len(targets)\n",
        "            val_loss += loss\n",
        "\n",
        "    avg_loss = val_loss / len(val_dl)\n",
        "    avg_acc = correct_examples / total_examples\n",
        "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "\n",
        "    history['val_loss'].append(avg_loss)\n",
        "    history['val_acc'].append(avg_acc)\n",
        "\n",
        "    if avg_acc > best_val_acc:\n",
        "        best_val_acc = avg_acc\n",
        "        if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "           os.makedirs(CHECKPOINT_FOLDER)\n",
        "        print(\"Saving ...\")\n",
        "        state = {'state_dict': net.state_dict(),\n",
        "                'epoch': i,\n",
        "                'lr': current_learning_rate}\n",
        "        torch.save(state, os.path.join(CHECKPOINT_FOLDER, 'inceptionv1.pth'))\n",
        "\n",
        "    print('')\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"Optimization finished: best validation accuracy is {best_val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show the plots of the training and validation losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "V7ODc8NG_cOR",
        "outputId": "eb3dd695-583a-4277-fa97-5daf382e7f9d"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "  accuracies = [x.cpu().item() for x in history['val_acc']]\n",
        "  plt.plot(accuracies,'-x')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title(\"Accuracy Vs No. of Epochs\")\n",
        "\n",
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_losses(history):\n",
        "  train_losses = [x.cpu().item() for x in history['train_loss']]\n",
        "  val_losses = [x.cpu().item() for x in history['val_loss']]\n",
        "  plt.plot(train_losses,'-bx')\n",
        "  plt.plot(val_losses,'-rx')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend(['Training','Validation'])\n",
        "  plt.title(\"Loss Vs No. of Epochs\")\n",
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the model with the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "n2cyP8TJkvIw",
        "outputId": "3a7a11f7-703b-4321-904f-dbe0fc0c6fee"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm.tqdm(test_dl, \"evaluating...\"):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "conf_mat = confusion_matrix(true_labels,predicted_labels)\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Reds\", cbar=False, xticklabels=class_names,yticklabels=class_names)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Modelling Corn Disease')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional testing on images with different backgrounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "net.eval()\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm.tqdm(diffBg_dl, \"evaluating...\"):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "conf_mat = confusion_matrix(true_labels,predicted_labels)\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Reds\", cbar=False, xticklabels=class_names,yticklabels=class_names)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Diff BG')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
