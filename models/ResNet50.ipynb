{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOTS5m3f_cON"
      },
      "source": [
        "### Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxtDWpGD_cOO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "from tqdm import notebook as tqdm\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Normalize\n",
        "from torchvision.transforms import RandomVerticalFlip\n",
        "from torchvision.transforms import RandomHorizontalFlip\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qib0Py_1_cOO"
      },
      "source": [
        "## Loading and Pre Processing Data\n",
        "\n",
        "Resizing the images (so they each have the same amount of pixels, not to overfit to larger images) and converting them to Tensor, so they can be used in the model.\n",
        "\n",
        "Import the data from Google Drive as we assume that this is running on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV5Neyg4_cOP"
      },
      "outputs": [],
      "source": [
        "means = [0.43766510486602783, 0.49804747104644775, 0.3756938874721527]\n",
        "stds = [0.16779577732086182, 0.1552586406469345, 0.1632111817598343]\n",
        "transform_train = Compose([RandomHorizontalFlip(), RandomVerticalFlip(), Resize(size=(64,64)), ToTensor(),Normalize(mean=means, std=stds)])\n",
        "transform_val = Compose([Resize(size=(64,64)), ToTensor(),Normalize(mean=means, std=stds)])\n",
        "transform_test = Compose([Resize(size=(64,64)), ToTensor(),Normalize(mean=means, std=stds)])\n",
        "\n",
        "train_dataset = ImageFolder(root=\"/content/drive/MyDrive/splitted_data/train\",transform=transform_train)\n",
        "val_dataset = ImageFolder(root=\"/content/drive/MyDrive/splitted_data/val\",transform=transform_val)\n",
        "test_dataset = ImageFolder(root=\"/content/drive/MyDrive/splitted_data/test\",transform=transform_test)\n",
        "diffBg_dataset = ImageFolder(root=\"/content/drive/MyDrive/diffBg\",transform=transform_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh1v9Eub_cOP"
      },
      "source": [
        "### Use a GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2xo6E8M_cOP",
        "outputId": "d2421910-2bd1-4527-8b4d-2a4440b2b816"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NULTmc88_cOQ"
      },
      "source": [
        "## Defining the ResNet50 Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEZ8yS1N_cOQ"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "        \n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "        \n",
        "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        \n",
        "        #downsample if needed\n",
        "        if self.i_downsample is not None:\n",
        "            identity = self.i_downsample(identity)\n",
        "        #add identity\n",
        "        x+=identity\n",
        "        x=self.relu(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "       \n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.i_downsample = i_downsample\n",
        "        self.stride = stride\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      identity = x.clone()\n",
        "\n",
        "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
        "      x = self.batch_norm2(self.conv2(x))\n",
        "\n",
        "      if self.i_downsample is not None:\n",
        "          identity = self.i_downsample(identity)\n",
        "      print(x.shape)\n",
        "      print(identity.shape)\n",
        "      x += identity\n",
        "      x = self.relu(x)\n",
        "      return x   \n",
        "        \n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
        "        \n",
        "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
        "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
        "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
        "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
        "        x = self.max_pool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
        "        ii_downsample = None\n",
        "        layers = []\n",
        "        \n",
        "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
        "            ii_downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
        "            )\n",
        "            \n",
        "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
        "        self.in_channels = planes*ResBlock.expansion\n",
        "        \n",
        "        for i in range(blocks-1):\n",
        "            layers.append(ResBlock(self.in_channels, planes))\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def ResNet50(channels=3):\n",
        "    return ResNet(Bottleneck, [3,4,6,3], 4, channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform a sanity check for the correctness of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = ResNet50()\n",
        "net = net.to(device)\n",
        "data = torch.randn(5,3,64,64)\n",
        "data = data.to(device)\n",
        "out = net.forward(data)\n",
        "assert(out.detach().cpu().numpy().shape == (5,4))\n",
        "print(\"Forward pass successful, shape matches\")\n",
        "\n",
        "for layer in net.children():\n",
        "  print(layer)\n",
        "  print(sum(p.numel() for p in layer.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7ZESNKI_cOQ"
      },
      "source": [
        "### Move data and the model to the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddi0gqrJ_cOQ",
        "outputId": "c51d444c-06ea-4ab4-e43d-52c5fe550bb6"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size=128, shuffle=True)\n",
        "test_dl = DataLoader(test_dataset, batch_size=16)\n",
        "diffBg_dl = DataLoader(diffBg_dataset, batch_size=16)\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining a Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "INITIAL_LR = 0.1 # initial learning rate\n",
        "MOMENTUM = 0.9 # momentum for optimizer\n",
        "\n",
        "REG = 1e-3 # L2 regularization strength\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "\n",
        "# Add optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay = REG)\n",
        "EPOCHS = 30\n",
        "CHECKPOINT_FOLDER = \"./saved_model\"\n",
        "\n",
        "best_val_acc = 0\n",
        "current_learning_rate = INITIAL_LR\n",
        "\n",
        "DECAY_EPOCHS = 10\n",
        "DECAY = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "for i in range(0, EPOCHS):\n",
        "    if i % DECAY_EPOCHS == 0 and i != 0:\n",
        "        current_learning_rate = current_learning_rate * DECAY\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = current_learning_rate\n",
        "        print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "\n",
        "    net.train() # switch to train mode\n",
        "\n",
        "    print(\"Epoch %d:\" %i)\n",
        "    total_examples = 0\n",
        "    correct_examples = 0\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    # 1 epoch training\n",
        "    for batch_idx, (inputs, targets) in tqdm.tqdm(enumerate(train_dl), \"training...\"):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = net.forward(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # count the number of correctly predicted samples in the current batch\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1) \n",
        "        correct = predicted.eq(targets).sum()\n",
        "\n",
        "        correct_examples += correct\n",
        "        total_examples += len(targets)\n",
        "        train_loss += loss\n",
        "\n",
        "    avg_loss = train_loss / len(train_dl)\n",
        "    avg_acc = correct_examples / total_examples\n",
        "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
        "    \n",
        "    history['train_loss'].append(avg_loss)\n",
        "    history['train_acc'].append(avg_acc)\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    total_examples = 0\n",
        "    correct_examples = 0\n",
        "\n",
        "    val_loss = 0 \n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in tqdm.tqdm(enumerate(val_dl), \"validating...\"):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = net.forward(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct = predicted.eq(targets).sum()\n",
        "\n",
        "            correct_examples += correct\n",
        "            total_examples += len(targets)\n",
        "            val_loss += loss\n",
        "\n",
        "    avg_loss = val_loss / len(val_dl)\n",
        "    avg_acc = correct_examples / total_examples\n",
        "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "\n",
        "    history['val_loss'].append(avg_loss)\n",
        "    history['val_acc'].append(avg_acc)\n",
        "\n",
        "    if avg_acc > best_val_acc:\n",
        "        best_val_acc = avg_acc\n",
        "        if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "           os.makedirs(CHECKPOINT_FOLDER)\n",
        "        print(\"Saving ...\")\n",
        "        state = {'state_dict': net.state_dict(),\n",
        "                'epoch': i,\n",
        "                'lr': current_learning_rate}\n",
        "        torch.save(state, os.path.join(CHECKPOINT_FOLDER, 'resnet50.pth'))\n",
        "\n",
        "    print('')\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"Optimization finished: best validation accuracy is {best_val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show the plots of the training and validation losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "V7ODc8NG_cOR",
        "outputId": "eb3dd695-583a-4277-fa97-5daf382e7f9d"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "  accuracies = [x.cpu().item() for x in history['val_acc']]\n",
        "  plt.plot(accuracies,'-x')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title(\"Accuracy Vs No. of Epochs\")\n",
        "\n",
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_losses(history):\n",
        "  train_losses = [x.cpu().item() for x in history['train_loss']]\n",
        "  val_losses = [x.cpu().item() for x in history['val_loss']]\n",
        "  plt.plot(train_losses,'-bx')\n",
        "  plt.plot(val_losses,'-rx')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend(['Training','Validation'])\n",
        "  plt.title(\"Loss Vs No. of Epochs\")\n",
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the model with the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "n2cyP8TJkvIw",
        "outputId": "3a7a11f7-703b-4321-904f-dbe0fc0c6fee"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm.tqdm(test_dl, \"evaluating...\"):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "conf_mat = confusion_matrix(true_labels,predicted_labels)\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Reds\", cbar=False, xticklabels=class_names,yticklabels=class_names)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Modelling Corn Disease')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional testing on images with different backgrounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "net.eval()\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm.tqdm(diffBg_dl, \"evaluating...\"):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predicted_labels.extend(predicted.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "conf_mat = confusion_matrix(true_labels,predicted_labels)\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Reds\", cbar=False, xticklabels=class_names,yticklabels=class_names)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Diff BG')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
