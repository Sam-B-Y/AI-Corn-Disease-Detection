{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOTS5m3f_cON"
      },
      "source": [
        "### Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxtDWpGD_cOO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import google.drive as drive\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import Normalize\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.transforms import GaussianBlur\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qib0Py_1_cOO"
      },
      "source": [
        "## Loading and Pre Processing Data\n",
        "\n",
        "Resizing the images (so they each have the same amount of pixels, not to overfit to larger images) and converting them to Tensor, so they can be used in the model.\n",
        "\n",
        "Import the data from Google Drive as we assume that this is running on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV5Neyg4_cOP"
      },
      "outputs": [],
      "source": [
        "means = [0.4375447928905487, 0.4979252815246582, 0.3755785822868347]\n",
        "stds = [0.17900893092155457, 0.16678600013256073, 0.17380985617637634]\n",
        "transformTrain = Compose([Resize(size=(150,150)), GaussianBlur(), ToTensor(),Normalize(mean=means, std=stds)])\n",
        "transformValTest = Compose([Resize(size=(150,150)), GaussianBlur(), ToTensor(),Normalize(mean=means, std=stds)])\n",
        "\n",
        "train_dataset = ImageFolder(root=\"/content/drive/MyDrive/splitted_data/train\",transform=transformTrain)\n",
        "val_dataset = ImageFolder(root=\"/content/drive/MyDrive/splitted_data/val\",transform=transformValTest)\n",
        "test_dataset = ImageFolder(root=\"/content/drive/MyDrive/splitted_data/test\",transform=transformValTest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh1v9Eub_cOP"
      },
      "source": [
        "### Use a GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2xo6E8M_cOP",
        "outputId": "d2421910-2bd1-4527-8b4d-2a4440b2b816"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjBWNxAE_cOP"
      },
      "source": [
        "### Defining functions to evaluate the model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_56mNOJ_cOQ"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, labels)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, labels)\n",
        "        acc = accuracy(out, labels)\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NULTmc88_cOQ"
      },
      "source": [
        "## Defining the ResNet9 Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEZ8yS1N_cOQ"
      },
      "outputs": [],
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU(inplace = True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = conv_block(in_channels, 64)                               # 64  x 150 x 150\n",
        "        self.conv2 = conv_block(64, 128, pool=True)                            # 128 x 75  x 75\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))  # 128 x 75  x 75\n",
        "\n",
        "        self.conv3 = conv_block(128, 256, pool=True)                           # 256 x 37  x 37\n",
        "        self.conv4 = conv_block(256, 512, pool=True)                           # 512 x 18  x 18\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))  # 512 x 18  x 18\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(18),                      # 512 x 1   x 1\n",
        "                                        nn.Flatten(),                          # 512\n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512, num_classes))           # 512 --> 10\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7ZESNKI_cOQ"
      },
      "source": [
        "### Move data and the model to the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddi0gqrJ_cOQ",
        "outputId": "c51d444c-06ea-4ab4-e43d-52c5fe550bb6"
      },
      "outputs": [],
      "source": [
        "train_dl=DeviceDataLoader(DataLoader(train_dataset,pin_memory=True, batch_size=16),device)\n",
        "val_dl=DeviceDataLoader(DataLoader(val_dataset,pin_memory=True, batch_size=16),device)\n",
        "test_dl=DeviceDataLoader(DataLoader(test_dataset,pin_memory=True, batch_size=16),device)\n",
        "\n",
        "model=to_device(ResNet9(3,6),device)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparing the training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfE_CLnJ_cOR",
        "outputId": "da599dd6-88b0-4d8a-b3f9-b01fd8a65244"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,steps_per_epoch=len(train_loader))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history\n",
        "\n",
        "history=[evaluate(model,val_dl)]\n",
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the model using One Cycle Learning Rate Policy\n",
        "\n",
        "Parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs=10\n",
        "max_lr=0.01\n",
        "grad_clip=0.1\n",
        "weight_decay=1e-4\n",
        "opt_func= torch.optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nGRWCTa_cOR",
        "outputId": "8703bd8d-d4d6-43bf-f32d-84357c581782"
      },
      "outputs": [],
      "source": [
        "%time\n",
        "\n",
        "history+=fit_one_cycle(epochs,max_lr,model,train_dl,val_dl,grad_clip=grad_clip,weight_decay=weight_decay,opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show the plots of the training and validation losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "V7ODc8NG_cOR",
        "outputId": "eb3dd695-583a-4277-fa97-5daf382e7f9d"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "  accuracies = [x.get('val_acc') for x in history]\n",
        "  plt.plot(accuracies,'-x')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title(\"Accuracy Vs No. of Epochs\")\n",
        "\n",
        "def plot_losses(history):\n",
        "  train_losses = [x.get('train_loss') for x in history]\n",
        "  val_losses = [x['val_loss'] for x in history]\n",
        "  plt.plot(train_losses,'-bx')\n",
        "  plt.plot(val_losses,'-rx')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend(['Training','Validation'])\n",
        "  plt.title(\"Loss Vs No. of Epochs\")\n",
        "\n",
        "def plot_lrs(history):\n",
        "  lrs = np.concatenate([x.get('lrs',[]) for x in history])\n",
        "  plt.plot(lrs)\n",
        "  plt.xlabel('Batch no.')\n",
        "  plt.ylabel('Learning Rate')\n",
        "  plt.title('Learning Rate Vs Batch No.')\n",
        "\n",
        "print(plot_accuracies(history))\n",
        "print(plot_losses(history))\n",
        "print(plot_lrs(history))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the model with the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "n2cyP8TJkvIw",
        "outputId": "3a7a11f7-703b-4321-904f-dbe0fc0c6fee"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, data_loader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            images, targets = batch\n",
        "            predictions = model(images)\n",
        "            _, predicted_labels = torch.max(predictions, dim=1)\n",
        "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "    return all_predictions, all_targets\n",
        "\n",
        "def calculate_metrics(predictions, targets):\n",
        "    cm = confusion_matrix(targets, predictions)\n",
        "    recall = np.diag(cm) / np.sum(cm, axis=1)\n",
        "    precision = np.diag(cm) / np.sum(cm, axis=0)\n",
        "    return cm, recall, precision\n",
        "\n",
        "predictions, targets = get_predictions(model, test_dl)\n",
        "cm, recall, precision = calculate_metrics(predictions, targets)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
